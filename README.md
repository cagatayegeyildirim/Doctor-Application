# Doctor Application
Python-Flask Doctor Application NGINX and PostgreSQL

During my summer internship, I learned about microservice and container technology and learned how to use them in the software field and how software is set up in the DevOps field. First, I learned how to containerize applications using Docker (a container application). Then I tried Docker on the Linux server by installing it on text-based Linux. After learning a little about these topics and learning how to containerize applications, my advisor asked me to apply what I learned to a larger project. So, I decided to make a web-based patient management application for doctors. I made the project using the Python language. First, I researched how to do this since I have never built a web-based application using Python. Then I decided to use Python's library, Flask. Thanks to this library, I was able to use HTML and CSS code in my Python code. Then I needed a database for my patient management application. I used Sqlite3, which is a database library for my data in Python. Then I used the Figma (design) program for the interface of my web-based application. After my application was finished, I installed two different Linux servers. This was because the database was running in my separate application. Thus, when I make an update in my application, the data cannot be changed in the database by mistake. It's safer for my application to work separately for each part. During installation on servers, I learned that Sqlite3 is only based on localhost and cannot receive data from other servers. Then, to solve this problem, I removed the SQLite3 library and used the PostgreSQL library. Thus, I was able to connect from the server where my application is located to the server where the database is located. I installed Python, Flask, and PostgreSQL on my first server. I installed PostgreSQL on my other server. After the installations were finished and my project was running successfully, I tried to run my application in the Kubernetes environment. In addition, I installed two more servers, one running as a master node and the other as a worker node. After making the necessary installations on the master node and the worker node, I turned my application into a container with Docker. Then I uploaded this container I created to Docker Hub. I then uploaded this container file to my server. As a result, if my program crashes or is deleted for certain reasons, the container runs again in the Kubernetes environment I created, preventing possible interruptions.
